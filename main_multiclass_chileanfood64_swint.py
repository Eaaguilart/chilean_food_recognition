import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

sns.set(style='darkgrid', palette='cubehelix')

from tensorflow.keras.models import Sequential
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import regularizers, optimizers
from tensorflow.python.client import device_lib
from scheduler import *
from swintransformer import SwinTransformer

root = "/home/eduardo-ucn/Documents/datasets/ChileanFood64/"

train_df = pd.read_csv(root+"trainLabels.csv",dtype=str)
test_df  = pd.read_csv(root+"testLabels.csv",dtype=str)
valid_df = pd.read_csv(root+"validLabels.csv",dtype=str)

print(train_df.head()["path"][0])

datagen = ImageDataGenerator(rescale=1./255,
                             featurewise_center=False,
                             samplewise_center=False,
                             featurewise_std_normalization=False,
                             samplewise_std_normalization=False,
                             zca_whitening=False,
                             rotation_range=20, # stratospark usa 0
                             width_shift_range=0.2,
                             height_shift_range=0.2,
                             horizontal_flip=True,
                             vertical_flip=False,
                             shear_range=0.2,
                             zoom_range=[.8, 1],
                             channel_shift_range=30,
                             fill_mode="reflect")

valid_datagen = ImageDataGenerator(rescale=1./255)

IMG_SIZE_LIST = [256, 274, 296, 342, 434]
CROP_SIZE_LIST = [224, 240, 260, 300, 380]
MODELS = ["b0","b1","b2","b3","b4"]

MODEL = "b0"
batch_size = 16
IMG_SIZE = IMG_SIZE_LIST[MODELS.index(MODEL)]
CROP_SIZE = CROP_SIZE_LIST[MODELS.index(MODEL)]

train_generator=datagen.flow_from_dataframe(dataframe=train_df,
                                            directory=root,
                                            x_col="path",
                                            y_col="label",
                                            batch_size=batch_size,
                                            seed=42,
                                            shuffle=True,
                                            class_mode="categorical",
                                            validate_filenames=False,
                                            target_size=(IMG_SIZE,IMG_SIZE))

valid_generator=valid_datagen.flow_from_dataframe(dataframe=valid_df,
                                                directory=root,
                                                x_col="path",
                                                y_col="label",
                                                batch_size=batch_size,
                                                seed=42,
                                                shuffle=False,
                                                class_mode="categorical",
                                                validate_filenames=False,
                                                target_size=(CROP_SIZE,CROP_SIZE))
test_generator=valid_datagen.flow_from_dataframe(dataframe=test_df,
                                                directory=root,
                                                x_col="path",
                                                y_col="label",
                                                batch_size=1,
                                                seed=42,
                                                shuffle=False,
                                                class_mode="categorical",
                                                validate_filenames=False,
                                                target_size= (CROP_SIZE,CROP_SIZE))    


def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def center_crop(x, center_crop_size, **kwargs):
    centerw, centerh = x.shape[0]//2, x.shape[1]//2
    halfw, halfh = center_crop_size[0]//2, center_crop_size[1]//2
    return x[centerw-halfw:centerw+halfw,centerh-halfh:centerh+halfh, :] 

def center_crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = center_crop(batch_x[i], (crop_length,crop_length))
        yield (batch_crops, batch_y)



train_crops = crop_generator(train_generator, crop_length=CROP_SIZE)
test_crops = crop_generator(test_generator, crop_length=CROP_SIZE)

STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size
STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size
STEP_SIZE_TEST = test_generator.n//test_generator.batch_size

print('Tamaño: {}'.format(STEP_SIZE_TRAIN))
print('Tamaño: {}'.format(STEP_SIZE_VALID))

'''
import os
from PIL import Image
folder_path = root+'train'
extensions = []
for fldr in os.listdir(folder_path):
    sub_folder_path = os.path.join(folder_path, fldr)
    for filee in os.listdir(sub_folder_path):
        file_path = os.path.join(sub_folder_path, filee)
        print('** Path: {}  **'.format(file_path), end="\r", flush=True)
        try:
            im = Image.open(file_path)
            rgb_im = im.convert('RGB')
            if filee.split('.')[1] not in extensions:
                extensions.append(filee.split('.')[1])
        except Exception as e:
            print(e)
'''

IMAGE_SIZE_ST = (224,224)
NUM_CLASSES = 64

model = tf.keras.Sequential([
  #tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(tf.cast(data, tf.float32), mode="torch"), input_shape=[*IMAGE_SIZE_ST, 3]),
  tf.keras.layers.Input(shape=(224,224,3 )),
  SwinTransformer('swin_tiny_224', include_top=False, pretrained=True),
  tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')
])


def custom_scheduler(max_epochs):
    def scheduler(epoch, lr):
        if(epoch == 0):
            lr = lr
        else:
            if (epoch % 8 == 0):
                lr = (lr*0.2) #epochs comienzan en 0 , cambiar 0.2 !
        return lr
    return scheduler


train_crops = crop_generator(train_generator, crop_length=CROP_SIZE)

learning_rate       =  0.0002
epochs              =  40

model.compile(loss="categorical_crossentropy",
              optimizer=optimizers.Adam(lr=learning_rate), 
              metrics=["accuracy", tf.keras.metrics.TopKCategoricalAccuracy(k=5)], run_eagerly=True)

model.load_weights("chileanfood64_swint_tiny_bs16.h5")
model.trainable=False
model.summary()
#model.evaluate(test_crops, batch_size=test_generator.batch_size, steps=STEP_SIZE_TEST)


from sklearn import metrics

def compute_statistics (y_true, y_pred, y_score):
    recall_score = round(metrics.recall_score(y_true, y_pred, average='macro'), 4)
    f1_score = round(metrics.f1_score(y_true, y_pred, average='macro'), 4)
    precision_score = round(metrics.precision_score(y_true, y_pred, average='macro'), 4)
    topk_acc = round(metrics.top_k_accuracy_score(y_true,y_score,k=5),4)
    acc = round(metrics.accuracy_score(y_true,y_pred),4)
    return recall_score, precision_score, f1_score, topk_acc, acc

y_score = model.predict_generator(test_crops, STEP_SIZE_TEST)
y_pred = np.argmax(y_score, -1)
y_true = test_generator.classes
print(np.shape(y_pred), np.shape(y_true))
print(compute_statistics (y_true, y_pred, y_score))
'''
X = next(test_crops)[0]
print(np.shape(X))
import time
init_time = time.time()
model.predict(X)
print(time.time()-init_time)
'''
'''
callbacks = [LearningRateScheduler(custom_scheduler(epochs)),
             tf.keras.callbacks.ModelCheckpoint("chileanfood64_swint_tiny_bs16.h5", monitor="val_loss", save_best_only=True, save_weights_only=True),
             tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=8)]


model.compile(loss="categorical_crossentropy",
              optimizer=optimizers.Adam(lr=learning_rate), 
              metrics=["accuracy"], run_eagerly=True)
model.summary()
model.fit(train_crops, 
          steps_per_epoch = STEP_SIZE_TRAIN,
          epochs=epochs,
          validation_data = valid_generator,
          validation_steps = STEP_SIZE_VALID,
          callbacks=callbacks,
          verbose=1)

'''
